{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5ca3afc7",
      "metadata": {
        "id": "5ca3afc7",
        "papermill": {
          "duration": 4.851116,
          "end_time": "2023-11-09T14:36:53.679298",
          "exception": false,
          "start_time": "2023-11-09T14:36:48.828182",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from sklearn.utils import shuffle\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "da221462",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:36:53.705056Z",
          "iopub.status.busy": "2023-11-09T14:36:53.704580Z",
          "iopub.status.idle": "2023-11-09T14:36:53.773069Z",
          "shell.execute_reply": "2023-11-09T14:36:53.772174Z"
        },
        "id": "da221462",
        "outputId": "34fd2431-674e-4721-cec7-ca2baf025419",
        "papermill": {
          "duration": 0.083336,
          "end_time": "2023-11-09T14:36:53.775039",
          "exception": false,
          "start_time": "2023-11-09T14:36:53.691703",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4e1235be",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:36:53.800792Z",
          "iopub.status.busy": "2023-11-09T14:36:53.800447Z",
          "iopub.status.idle": "2023-11-09T14:36:53.805259Z",
          "shell.execute_reply": "2023-11-09T14:36:53.804370Z"
        },
        "id": "4e1235be",
        "outputId": "3f72a2eb-a5fb-4d4d-9589-2773bcff1f07",
        "papermill": {
          "duration": 0.019997,
          "end_time": "2023-11-09T14:36:53.807313",
          "exception": false,
          "start_time": "2023-11-09T14:36:53.787316",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Renuka\\Desktop\\prodigy task 5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e558bc3",
      "metadata": {
        "id": "8e558bc3",
        "papermill": {
          "duration": 0.011979,
          "end_time": "2023-11-09T14:36:53.831376",
          "exception": false,
          "start_time": "2023-11-09T14:36:53.819397",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        " **understanding the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "fd913936",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:36:53.881573Z",
          "iopub.status.busy": "2023-11-09T14:36:53.880702Z",
          "iopub.status.idle": "2023-11-09T14:43:56.001673Z",
          "shell.execute_reply": "2023-11-09T14:43:56.000511Z"
        },
        "id": "fd913936",
        "outputId": "87856f69-41ef-4abe-f928-d3d538eca07f",
        "papermill": {
          "duration": 425.518296,
          "end_time": "2023-11-09T14:43:59.385687",
          "exception": false,
          "start_time": "2023-11-09T14:36:53.867391",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading the data...\n",
            "Dataset downloaded!\n",
            "Extracting data..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction done!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n"
          ]
        }
      ],
      "source": [
        "if \"food-101\" in os.listdir():\n",
        "    print(\"Dataset already exists\")\n",
        "else:\n",
        "    print(\"Downloading the data...\")\n",
        "    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "    print(\"Dataset downloaded!\")\n",
        "    print(\"Extracting data..\")\n",
        "    !tar xzvf food-101.tar.gz > /dev/null 2>&1\n",
        "    print(\"Extraction done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bcb804f8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:43:59.759593Z",
          "iopub.status.busy": "2023-11-09T14:43:59.758635Z",
          "iopub.status.idle": "2023-11-09T14:43:59.767234Z",
          "shell.execute_reply": "2023-11-09T14:43:59.766393Z"
        },
        "id": "bcb804f8",
        "outputId": "2170b2c3-b83b-49af-e1dd-888620a3f445",
        "papermill": {
          "duration": 0.191855,
          "end_time": "2023-11-09T14:43:59.769240",
          "exception": false,
          "start_time": "2023-11-09T14:43:59.577385",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File not found: ./food-101/meta/classes.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "file_path = \"./food-101/meta/classes.txt\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        classes = file.read().splitlines()\n",
        "    classes_21 = classes[:20] + ['other']\n",
        "    print(classes_21, len(classes_21))\n",
        "else:\n",
        "    print(f\"File not found: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c03376c",
      "metadata": {
        "id": "3c03376c",
        "papermill": {
          "duration": 0.142586,
          "end_time": "2023-11-09T14:44:00.055971",
          "exception": false,
          "start_time": "2023-11-09T14:43:59.913385",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**identifying training and testing images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "6abf4d41",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:00.366113Z",
          "iopub.status.busy": "2023-11-09T14:44:00.365401Z",
          "iopub.status.idle": "2023-11-09T14:44:04.173131Z",
          "shell.execute_reply": "2023-11-09T14:44:04.171437Z"
        },
        "id": "6abf4d41",
        "outputId": "a0236b40-7cbd-44e6-907e-e74bb824ba33",
        "papermill": {
          "duration": 3.97715,
          "end_time": "2023-11-09T14:44:04.176217",
          "exception": false,
          "start_time": "2023-11-09T14:44:00.199067",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"Testing images\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'head' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-e \"\\nTraining images\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'head' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "#The code snippet displays the first five entries from two files, test.txt and train.txt, located in the food-101/meta/ directory. It begins by printing \"Testing images,\" followed by the first five lines from test.txt, then prints \"Training images\" and shows the first five lines from train.txt. The purpose is to preview the contents of these files, likely listing image data for testing and training purposes.\n",
        "!echo \"Testing images\"\n",
        "!head -n 5 ./food-101/meta/test.txt\n",
        "!echo -e \"\\nTraining images\"\n",
        "!head -n 5 ./food-101/meta/train.txt | head -n 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70861dd4",
      "metadata": {
        "id": "70861dd4",
        "papermill": {
          "duration": 0.143033,
          "end_time": "2023-11-09T14:44:04.474320",
          "exception": false,
          "start_time": "2023-11-09T14:44:04.331287",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**exploratory data analysis (for dummies)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f3f9d8ee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:04.764477Z",
          "iopub.status.busy": "2023-11-09T14:44:04.764106Z",
          "iopub.status.idle": "2023-11-09T14:44:04.772008Z",
          "shell.execute_reply": "2023-11-09T14:44:04.771096Z"
        },
        "id": "f3f9d8ee",
        "papermill": {
          "duration": 0.154992,
          "end_time": "2023-11-09T14:44:04.773887",
          "exception": false,
          "start_time": "2023-11-09T14:44:04.618895",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def prep_df(path: str) -> pd.DataFrame:\n",
        "    array = open(path, 'r').read().splitlines()\n",
        "    \n",
        "    # Getting the full path for the images\n",
        "    df = pd.DataFrame(array, columns=['relative_path'])\n",
        "    \n",
        "    # Shuffling the rows of the DataFrame randomly\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2b52b2f5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:05.061677Z",
          "iopub.status.busy": "2023-11-09T14:44:05.061345Z",
          "iopub.status.idle": "2023-11-09T14:44:05.582286Z",
          "shell.execute_reply": "2023-11-09T14:44:05.581295Z"
        },
        "id": "2b52b2f5",
        "outputId": "1ff6a2a2-9a06-43e0-c677-02c6b2405298",
        "papermill": {
          "duration": 0.667279,
          "end_time": "2023-11-09T14:44:05.584395",
          "exception": false,
          "start_time": "2023-11-09T14:44:04.917116",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def prep_df(path: str) -> pd.DataFrame:\n",
        "    array = open(path, 'r').read().splitlines()\n",
        "    \n",
        "    # Getting the full path for the images\n",
        "    df = pd.DataFrame(array, columns=['relative_path'])\n",
        "    \n",
        "    # Shuffling the rows of the DataFrame randomly\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "deb0a248",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:05.875993Z",
          "iopub.status.busy": "2023-11-09T14:44:05.875189Z",
          "iopub.status.idle": "2023-11-09T14:44:08.546668Z",
          "shell.execute_reply": "2023-11-09T14:44:08.545696Z"
        },
        "id": "deb0a248",
        "outputId": "e8a86c54-d08d-48eb-ed89-0a22b5960a6a",
        "papermill": {
          "duration": 2.825544,
          "end_time": "2023-11-09T14:44:08.556496",
          "exception": false,
          "start_time": "2023-11-09T14:44:05.730952",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Now you can create your figure\n",
        "plt.figure(figsize=(20, 5))\n",
        "\n",
        "num_rows = 3\n",
        "num_cols = 8\n",
        "\n",
        "# Your code for visualizing the images goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986e882f",
      "metadata": {
        "id": "986e882f",
        "papermill": {
          "duration": 0.155376,
          "end_time": "2023-11-09T14:44:08.871748",
          "exception": false,
          "start_time": "2023-11-09T14:44:08.716372",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**visualization using barplot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e1373106",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:09.229215Z",
          "iopub.status.busy": "2023-11-09T14:44:09.228355Z",
          "iopub.status.idle": "2023-11-09T14:44:09.240056Z",
          "shell.execute_reply": "2023-11-09T14:44:09.239177Z"
        },
        "id": "e1373106",
        "papermill": {
          "duration": 0.21607,
          "end_time": "2023-11-09T14:44:09.242086",
          "exception": false,
          "start_time": "2023-11-09T14:44:09.026016",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def barplot_vis(imgs_dataframe):# Use the newly integrated Roboto font family for all text.\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    new_labels = [row if row in classes_21 else \"other\" for row in imgs_dataframe.label]\n",
        "    tmp_imgs_dataframe = imgs_dataframe.copy(deep=True)\n",
        "    tmp_imgs_dataframe['label'] = new_labels\n",
        "\n",
        "    grouped_train_imgs = tmp_imgs_dataframe.groupby(\"label\")\n",
        "\n",
        "    heights = [grouped_train_imgs.get_group(group).shape[0] for group in classes_21]\n",
        "\n",
        "    # Save the chart so we can loop through the bars below.\n",
        "    bars = ax.bar(\n",
        "        x=classes_21,\n",
        "        height=heights,\n",
        "        tick_label=classes_21\n",
        "    )\n",
        "\n",
        "    # Axis formatting.\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_color('#DDDDDD')\n",
        "    ax.tick_params(bottom=False, left=False)\n",
        "    ax.set_axisbelow(True)\n",
        "    ax.yaxis.grid(True, color='#EEEEEE')\n",
        "    ax.xaxis.grid(False)\n",
        "\n",
        "    # Add text annotations to the top of the bars.\n",
        "    bar_color = bars[0].get_facecolor()\n",
        "    percentage_heights = np.array(heights) / sum(heights)\n",
        "    for idx in range(len(bars)):\n",
        "      ax.text(\n",
        "          bars[idx].get_x() + bars[idx].get_width() / 2,\n",
        "          bars[idx].get_height() + 0.3,\n",
        "          round(percentage_heights[idx] * 100, 2),\n",
        "          horizontalalignment='center',\n",
        "          color=bar_color,\n",
        "          weight='bold'\n",
        "      )\n",
        "\n",
        "    # Add labels and a title.\n",
        "    ax.set_xlabel('Food Class', labelpad=15, color='#333333')\n",
        "    ax.set_ylabel('Number of Images', labelpad=15, color='#333333')\n",
        "    ax.set_title('Visualizing Class Imbalance', pad=15, color='#333333',\n",
        "                 weight='bold')\n",
        "\n",
        "    fig.autofmt_xdate(rotation=45)\n",
        "    fig.set_size_inches(18.5, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "17a8d0d6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:09.555600Z",
          "iopub.status.busy": "2023-11-09T14:44:09.554903Z",
          "iopub.status.idle": "2023-11-09T14:44:10.248942Z",
          "shell.execute_reply": "2023-11-09T14:44:10.247996Z"
        },
        "id": "17a8d0d6",
        "outputId": "46eaf277-7b7f-4655-ad48-640cade1b06b",
        "papermill": {
          "duration": 0.853134,
          "end_time": "2023-11-09T14:44:10.251072",
          "exception": false,
          "start_time": "2023-11-09T14:44:09.397938",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File not found: ./food-101/meta/train.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "file_path = \"./food-101/meta/train.txt\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        array = file.read().splitlines()\n",
        "    df = pd.DataFrame(array, columns=['relative_path'])\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(f\"File not found: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d6d032",
      "metadata": {
        "id": "28d6d032",
        "papermill": {
          "duration": 0.155861,
          "end_time": "2023-11-09T14:44:10.563710",
          "exception": false,
          "start_time": "2023-11-09T14:44:10.407849",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**preparing the data for transformation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6826e21a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:10.879499Z",
          "iopub.status.busy": "2023-11-09T14:44:10.879165Z",
          "iopub.status.idle": "2023-11-09T14:44:10.886400Z",
          "shell.execute_reply": "2023-11-09T14:44:10.885494Z"
        },
        "id": "6826e21a",
        "papermill": {
          "duration": 0.167078,
          "end_time": "2023-11-09T14:44:10.888402",
          "exception": false,
          "start_time": "2023-11-09T14:44:10.721324",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# import torchvision.transforms as transforms\n",
        "\n",
        "# Data augmentation for training\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Data augmentation for testing\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(255),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bed5f338",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:11.205323Z",
          "iopub.status.busy": "2023-11-09T14:44:11.204550Z",
          "iopub.status.idle": "2023-11-09T14:44:11.212342Z",
          "shell.execute_reply": "2023-11-09T14:44:11.211515Z"
        },
        "id": "bed5f338",
        "outputId": "266fa81a-01bf-4a36-dd72-5cbb18b1cded",
        "papermill": {
          "duration": 0.169753,
          "end_time": "2023-11-09T14:44:11.214485",
          "exception": false,
          "start_time": "2023-11-09T14:44:11.044732",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File not found: ./food-101/meta/classes.txt\n"
          ]
        }
      ],
      "source": [
        "## Assuming you have a file 'classes.txt' with the class names\n",
        "file_path = \"./food-101/meta/classes.txt\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        classes = file.read().splitlines()\n",
        "else:\n",
        "    print(f\"File not found: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4136a431",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:11.528240Z",
          "iopub.status.busy": "2023-11-09T14:44:11.527409Z",
          "iopub.status.idle": "2023-11-09T14:44:11.534877Z",
          "shell.execute_reply": "2023-11-09T14:44:11.533777Z"
        },
        "id": "4136a431",
        "papermill": {
          "duration": 0.166163,
          "end_time": "2023-11-09T14:44:11.536887",
          "exception": false,
          "start_time": "2023-11-09T14:44:11.370724",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Food20(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx, 0]\n",
        "        image = Image.open(img_path)\n",
        "        label = self.dataframe.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "90a1869a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:11.851876Z",
          "iopub.status.busy": "2023-11-09T14:44:11.851484Z",
          "iopub.status.idle": "2023-11-09T14:44:11.856365Z",
          "shell.execute_reply": "2023-11-09T14:44:11.855581Z"
        },
        "id": "90a1869a",
        "papermill": {
          "duration": 0.164246,
          "end_time": "2023-11-09T14:44:11.858265",
          "exception": false,
          "start_time": "2023-11-09T14:44:11.694019",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class Food20(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx, 0]\n",
        "        image = Image.open(img_path)\n",
        "        label = self.dataframe.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a8c8218d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:12.172102Z",
          "iopub.status.busy": "2023-11-09T14:44:12.171715Z",
          "iopub.status.idle": "2023-11-09T14:44:12.176790Z",
          "shell.execute_reply": "2023-11-09T14:44:12.175919Z"
        },
        "id": "a8c8218d",
        "papermill": {
          "duration": 0.164797,
          "end_time": "2023-11-09T14:44:12.178724",
          "exception": false,
          "start_time": "2023-11-09T14:44:12.013927",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Example paths\n",
        "source_dir = 'C:/Users/Renuka/Documents/all_images'\n",
        "target_dir = 'C:/Users/Renuka/Documents/train_data'\n",
        "\n",
        "# Example class names and corresponding image prefixes\n",
        "classes = ['class1', 'class2', 'class3']\n",
        "class_prefixes = {'class1': 'prefix1_', 'class2': 'prefix2_', 'class3': 'prefix3_'}\n",
        "\n",
        "# Create class directories\n",
        "for class_name in classes:\n",
        "    class_dir = os.path.join(target_dir, class_name)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "# Verify and create the source directory if it doesn't exist\n",
        "if not os.path.exists(source_dir):\n",
        "    os.makedirs(source_dir)\n",
        "\n",
        "# Move images to corresponding class directories\n",
        "if os.path.exists(source_dir):\n",
        "    for filename in os.listdir(source_dir):\n",
        "        for class_name, prefix in class_prefixes.items():\n",
        "            if filename.startswith(prefix):\n",
        "                shutil.move(os.path.join(source_dir, filename), os.path.join(target_dir, class_name, filename))\n",
        "                break\n",
        "else:\n",
        "    print(f\"The directory {source_dir} does not exist.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a86396c5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:12.493943Z",
          "iopub.status.busy": "2023-11-09T14:44:12.493566Z",
          "iopub.status.idle": "2023-11-09T14:44:12.666661Z",
          "shell.execute_reply": "2023-11-09T14:44:12.665317Z"
        },
        "id": "a86396c5",
        "outputId": "e9d25621-f05a-438d-fbfd-59e25a1c0b15",
        "papermill": {
          "duration": 0.332,
          "end_time": "2023-11-09T14:44:12.668803",
          "exception": false,
          "start_time": "2023-11-09T14:44:12.336803",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5847456",
      "metadata": {
        "id": "c5847456",
        "papermill": {
          "duration": 0.156254,
          "end_time": "2023-11-09T14:44:12.983417",
          "exception": false,
          "start_time": "2023-11-09T14:44:12.827163",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**creating the ML model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "cfc0183c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:13.298645Z",
          "iopub.status.busy": "2023-11-09T14:44:13.297819Z",
          "iopub.status.idle": "2023-11-09T14:44:16.374483Z",
          "shell.execute_reply": "2023-11-09T14:44:16.373491Z"
        },
        "id": "cfc0183c",
        "outputId": "2644434d-17bf-426b-c7fb-d5bab5f1cf48",
        "papermill": {
          "duration": 3.237151,
          "end_time": "2023-11-09T14:44:16.376780",
          "exception": false,
          "start_time": "2023-11-09T14:44:13.139629",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Fetch the pretrained weights for DenseNet-201 trained on ImageNet\n",
        "weights = models.DenseNet201_Weights.IMAGENET1K_V1\n",
        "\n",
        "# Initialize the DenseNet-201 model using these weights\n",
        "model = models.densenet201(weights=weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c7785756",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:16.697958Z",
          "iopub.status.busy": "2023-11-09T14:44:16.697575Z",
          "iopub.status.idle": "2023-11-09T14:44:16.705390Z",
          "shell.execute_reply": "2023-11-09T14:44:16.704520Z"
        },
        "id": "c7785756",
        "papermill": {
          "duration": 0.171046,
          "end_time": "2023-11-09T14:44:16.707382",
          "exception": false,
          "start_time": "2023-11-09T14:44:16.536336",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "1b0830b6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:17.026549Z",
          "iopub.status.busy": "2023-11-09T14:44:17.025931Z",
          "iopub.status.idle": "2023-11-09T14:44:21.092605Z",
          "shell.execute_reply": "2023-11-09T14:44:21.091187Z"
        },
        "id": "1b0830b6",
        "outputId": "8ff25f0d-306c-408c-e8a4-8ca6609283c2",
        "papermill": {
          "duration": 4.229675,
          "end_time": "2023-11-09T14:44:21.095860",
          "exception": false,
          "start_time": "2023-11-09T14:44:16.866185",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(<AddressFamily.AF_INET: 2>, 0, 0, '', ('20.207.73.82', 443))]\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "\n",
        "try:\n",
        "    # Attempt to resolve the hostname\n",
        "    print(socket.getaddrinfo('github.com', 443))\n",
        "except socket.gaierror as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "167450d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:21.524008Z",
          "iopub.status.busy": "2023-11-09T14:44:21.523199Z",
          "iopub.status.idle": "2023-11-09T14:44:24.626715Z",
          "shell.execute_reply": "2023-11-09T14:44:24.625813Z"
        },
        "id": "167450d3",
        "outputId": "add87207-fd7a-4cb0-d54d-0ab12d1f4298",
        "papermill": {
          "duration": 3.320787,
          "end_time": "2023-11-09T14:44:24.630606",
          "exception": false,
          "start_time": "2023-11-09T14:44:21.309819",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Renuka\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Renuka\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "C:\\Users\\Renuka\\AppData\\Local\\Temp\\ipykernel_16180\\1169004005.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'), strict=False)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Now you can define your classifier\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(1920, 1024),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(1024, 101),\n",
        ")\n",
        "\n",
        "# Assuming you have a pre-trained DenseNet-201 model\n",
        "model = models.densenet201(pretrained=True)\n",
        "model.classifier = classifier\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint_path = \"./food_classifier.pt\"\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'), strict=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f8115156",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:25.002991Z",
          "iopub.status.busy": "2023-11-09T14:44:25.002107Z",
          "iopub.status.idle": "2023-11-09T14:44:25.006535Z",
          "shell.execute_reply": "2023-11-09T14:44:25.005642Z"
        },
        "id": "f8115156",
        "papermill": {
          "duration": 0.168735,
          "end_time": "2023-11-09T14:44:25.008391",
          "exception": false,
          "start_time": "2023-11-09T14:44:24.839656",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#hyper parameters\n",
        "num_epochs = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "296b75d4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:25.331634Z",
          "iopub.status.busy": "2023-11-09T14:44:25.330971Z",
          "iopub.status.idle": "2023-11-09T14:44:25.348573Z",
          "shell.execute_reply": "2023-11-09T14:44:25.347718Z"
        },
        "id": "296b75d4",
        "papermill": {
          "duration": 0.181677,
          "end_time": "2023-11-09T14:44:25.350565",
          "exception": false,
          "start_time": "2023-11-09T14:44:25.168888",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c8ff41e",
      "metadata": {
        "id": "0c8ff41e",
        "papermill": {
          "duration": 0.167405,
          "end_time": "2023-11-09T14:44:25.677653",
          "exception": false,
          "start_time": "2023-11-09T14:44:25.510248",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**training and testing the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f441f742",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:26.008187Z",
          "iopub.status.busy": "2023-11-09T14:44:26.007850Z",
          "iopub.status.idle": "2023-11-09T14:44:26.016859Z",
          "shell.execute_reply": "2023-11-09T14:44:26.016079Z"
        },
        "id": "f441f742",
        "papermill": {
          "duration": 0.176499,
          "end_time": "2023-11-09T14:44:26.018812",
          "exception": false,
          "start_time": "2023-11-09T14:44:25.842313",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device):\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Setup train loss and train accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  print(\"--> Training Progress\")\n",
        "  # Loop through data loader data batches\n",
        "  for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
        "      # Send data to target device\n",
        "      images, labels = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      y_pred = model(images)\n",
        "\n",
        "      # 2. Calculate  and accumulate loss\n",
        "      loss = loss_fn(y_pred, labels)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # 3. Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 4. Loss backward\n",
        "      loss.backward()\n",
        "\n",
        "      # 5. Optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "      # Calculate and accumulate accuracy metric across all batches\n",
        "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "      train_acc += (y_pred_class == labels).sum().item()/len(y_pred)\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3d6573b4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:26.352441Z",
          "iopub.status.busy": "2023-11-09T14:44:26.352084Z",
          "iopub.status.idle": "2023-11-09T14:44:26.360289Z",
          "shell.execute_reply": "2023-11-09T14:44:26.359437Z"
        },
        "id": "3d6573b4",
        "papermill": {
          "duration": 0.177474,
          "end_time": "2023-11-09T14:44:26.362257",
          "exception": false,
          "start_time": "2023-11-09T14:44:26.184783",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device):\n",
        "  # Put model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # Setup test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # Turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "      print(\"--> Testing Progress\")\n",
        "      # Loop through DataLoader batches\n",
        "      for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
        "          # Send data to target device\n",
        "          images, labels = X.to(device), y.to(device)\n",
        "\n",
        "          # 1. Forward pass\n",
        "          test_pred_logits = model(images)\n",
        "\n",
        "          # 2. Calculate and accumulate loss\n",
        "          loss = loss_fn(test_pred_logits, labels)\n",
        "          test_loss += loss.item()\n",
        "\n",
        "          # Calculate and accumulate accuracy\n",
        "          test_pred_labels = torch.argmax(torch.softmax(test_pred_logits, dim=1), dim=1)\n",
        "\n",
        "          test_acc += ((test_pred_labels == labels).sum().item()/len(test_pred_labels))\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71858e5a",
      "metadata": {
        "id": "71858e5a",
        "papermill": {
          "duration": 0.165299,
          "end_time": "2023-11-09T14:44:26.691998",
          "exception": false,
          "start_time": "2023-11-09T14:44:26.526699",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "the code provides the machinery to train a deep learning model, assess its performance on a test dataset, and track and save the best-performing version of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "05c96af3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:27.023164Z",
          "iopub.status.busy": "2023-11-09T14:44:27.022479Z",
          "iopub.status.idle": "2023-11-09T14:44:27.033488Z",
          "shell.execute_reply": "2023-11-09T14:44:27.032580Z"
        },
        "id": "05c96af3",
        "papermill": {
          "duration": 0.177306,
          "end_time": "2023-11-09T14:44:27.035434",
          "exception": false,
          "start_time": "2023-11-09T14:44:26.858128",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device):\n",
        "  # Create empty results dictionary\n",
        "  history = {\n",
        "      \"train_loss\": [],\n",
        "      \"train_acc\": [],\n",
        "      \"test_loss\": [],\n",
        "      \"test_acc\": [],\n",
        "      'best train acc': (0, 0),\n",
        "      \"best_model\": dict()\n",
        "  }\n",
        "\n",
        "  # Loop through training and testing steps for a number of epochs\n",
        "  for epoch in range(epochs):\n",
        "      print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "\n",
        "      train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "      test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "      # Print out what's happening\n",
        "      print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "          f\"\\n\\n=============================\\n\"\n",
        "      )\n",
        "\n",
        "      # Update results dictionary\n",
        "      history[\"train_loss\"].append(train_loss)\n",
        "      history[\"train_acc\"].append(train_acc)\n",
        "      history[\"test_loss\"].append(test_loss)\n",
        "      history[\"test_acc\"].append(test_acc)\n",
        "      if test_loss < history[\"test_acc\"][len(history[\"test_acc\"]) - 1]:\n",
        "          history[\"best_model\"] = model.state_dict()\n",
        "\n",
        "      if test_acc > 0.95:\n",
        "         break\n",
        "\n",
        "  # Return the filled results at the end of the epochs\n",
        "  return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "e15a62bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T14:44:27.364359Z",
          "iopub.status.busy": "2023-11-09T14:44:27.363612Z",
          "iopub.status.idle": "2023-11-09T15:26:17.015389Z",
          "shell.execute_reply": "2023-11-09T15:26:17.014319Z"
        },
        "id": "e15a62bf",
        "outputId": "a4ba966e-e1e8-468a-af17-a3ae32313ae6",
        "papermill": {
          "duration": 2509.81817,
          "end_time": "2023-11-09T15:26:17.017617",
          "exception": false,
          "start_time": "2023-11-09T14:44:27.199447",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, optimizer, criterion, num_epochs, device):\n",
        "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'best_model': None}\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_acc'].append(epoch_acc.item())\n",
        "\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc.item())\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            history['best_model'] = model.state_dict()\n",
        "\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b80a135",
      "metadata": {
        "id": "2b80a135",
        "papermill": {
          "duration": 0.339839,
          "end_time": "2023-11-09T15:26:17.700082",
          "exception": false,
          "start_time": "2023-11-09T15:26:17.360243",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**viewing the learning history**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "e34ba21b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T15:26:18.385939Z",
          "iopub.status.busy": "2023-11-09T15:26:18.385553Z",
          "iopub.status.idle": "2023-11-09T15:26:18.394919Z",
          "shell.execute_reply": "2023-11-09T15:26:18.394142Z"
        },
        "id": "e34ba21b",
        "papermill": {
          "duration": 0.354473,
          "end_time": "2023-11-09T15:26:18.396860",
          "exception": false,
          "start_time": "2023-11-09T15:26:18.042387",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#this function is a utility to help visualize and compare the performance of a model on training and validation datasets across epochs.\n",
        "def plot_history(history):\n",
        "\n",
        "    loss = history['train_loss']\n",
        "    accuracy = history['train_acc']\n",
        "    val_loss = history['test_loss']\n",
        "    val_accuracy = history['test_acc']\n",
        "    x = range(len(loss))\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, accuracy, label='Training acc', color='#03045e', linewidth=2)\n",
        "    if len(val_loss) != 0:\n",
        "      plt.plot(x, val_accuracy, label='Validation acc', color='#48cae4', linewidth=2)\n",
        "    plt.plot(history['best train acc'][0],\n",
        "             history['best train acc'][1],\n",
        "             label='Best train acc', markersize=7, color='black')\n",
        "    plt.title('Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, label='Training loss', color='#03045e', linewidth=2)\n",
        "    if len(val_loss) != 0:\n",
        "      plt.plot(x, val_loss, label='Validation loss', color='#48cae4', linewidth=2)\n",
        "    plt.title('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "9c26c911",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T15:26:19.138987Z",
          "iopub.status.busy": "2023-11-09T15:26:19.138605Z",
          "iopub.status.idle": "2023-11-09T15:26:19.710017Z",
          "shell.execute_reply": "2023-11-09T15:26:19.709080Z"
        },
        "id": "9c26c911",
        "outputId": "9271f3ed-3aff-4a86-bdd7-9ba0a7e2645a",
        "papermill": {
          "duration": 0.917908,
          "end_time": "2023-11-09T15:26:19.711983",
          "exception": false,
          "start_time": "2023-11-09T15:26:18.794075",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
        "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abe3e21d",
      "metadata": {
        "id": "abe3e21d",
        "papermill": {
          "duration": 0.373169,
          "end_time": "2023-11-09T15:26:20.467557",
          "exception": false,
          "start_time": "2023-11-09T15:26:20.094388",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**evaluating the result using the required 21 classes only**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e1660f36",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T15:26:21.170579Z",
          "iopub.status.busy": "2023-11-09T15:26:21.169672Z",
          "iopub.status.idle": "2023-11-09T15:26:21.178011Z",
          "shell.execute_reply": "2023-11-09T15:26:21.177154Z"
        },
        "id": "e1660f36",
        "papermill": {
          "duration": 0.353469,
          "end_time": "2023-11-09T15:26:21.179813",
          "exception": false,
          "start_time": "2023-11-09T15:26:20.826344",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#the evaluate function measures and prints the classification accuracy of the model on a given dataset after adjusting classes to fit a 21-class problem (20 specific classes plus one \"other\" class).\n",
        "def evaluate(model, dataloader):\n",
        "\n",
        "  random = np.random.randint(0, len(dataloader))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "\n",
        "    for images, labels in tqdm(dataloader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "\n",
        "      preds = torch.argmax(torch.softmax(outputs, 1), 1)\n",
        "\n",
        "      # Converting this problem to a problem with 21 clases only\n",
        "      preds = np.array([pred.cpu() if pred < 20 else 20 for pred in preds])\n",
        "      labels = np.array([label.cpu() if label < 20 else 20 for label in labels])\n",
        "\n",
        "      n_samples += labels.shape[0]\n",
        "      n_correct += (preds==labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b8249cd4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T15:26:21.865851Z",
          "iopub.status.busy": "2023-11-09T15:26:21.865465Z",
          "iopub.status.idle": "2023-11-09T15:29:25.897782Z",
          "shell.execute_reply": "2023-11-09T15:29:25.896167Z"
        },
        "id": "b8249cd4",
        "outputId": "b9304b8d-247d-4f1a-969d-3cde961ccddc",
        "papermill": {
          "duration": 184.379788,
          "end_time": "2023-11-09T15:29:25.899809",
          "exception": false,
          "start_time": "2023-11-09T15:26:21.520021",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "cd214142",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T15:29:26.627463Z",
          "iopub.status.busy": "2023-11-09T15:29:26.627106Z",
          "iopub.status.idle": "2023-11-09T15:29:26.636206Z",
          "shell.execute_reply": "2023-11-09T15:29:26.635374Z"
        },
        "id": "cd214142",
        "outputId": "067e4329-9d68-472b-b7ac-119369a6e5b7",
        "papermill": {
          "duration": 0.372878,
          "end_time": "2023-11-09T15:29:26.638229",
          "exception": false,
          "start_time": "2023-11-09T15:29:26.265351",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File not found: ./food-101/meta/classes.txt\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have a file 'classes.txt' with the class names\n",
        "file_path = \"./food-101/meta/classes.txt\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        classes = file.read().splitlines()\n",
        "    classes_21 = classes[:20] + ['other']\n",
        "else:\n",
        "    print(f\"File not found: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07024eda",
      "metadata": {
        "id": "07024eda",
        "papermill": {
          "duration": 0.417932,
          "end_time": "2023-11-09T15:29:27.414809",
          "exception": false,
          "start_time": "2023-11-09T15:29:26.996877",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**visually evaluating the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ec0d60eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T15:29:28.137548Z",
          "iopub.status.busy": "2023-11-09T15:29:28.136643Z",
          "iopub.status.idle": "2023-11-09T15:29:28.148458Z",
          "shell.execute_reply": "2023-11-09T15:29:28.147523Z"
        },
        "id": "ec0d60eb",
        "papermill": {
          "duration": 0.37715,
          "end_time": "2023-11-09T15:29:28.150414",
          "exception": false,
          "start_time": "2023-11-09T15:29:27.773264",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#The visually_evaluate function aims to visually inspect the predictions made by a provided model using a random subset of images from a given DataFrame data_df.\n",
        "def visually_evaluate(model, data_df):\n",
        "    num_rows = 3\n",
        "    num_cols = 6\n",
        "\n",
        "    random_idx = np.random.randint(0, data_df.shape[0], num_rows*num_cols)\n",
        "\n",
        "    # Retrieve a number of images from the dataset.\n",
        "    imgs, labels = data_df.iloc[random_idx], data_df.iloc[random_idx].label\n",
        "    eval_dataset = Food20(imgs, transform=test_transforms)\n",
        "    eval_loader = DataLoader(eval_dataset, batch_size=num_rows*num_cols, shuffle=False)\n",
        "    eval_set = next(iter(eval_loader))\n",
        "\n",
        "    # Get predictions from model.\n",
        "    model.eval()\n",
        "    preds = model(eval_set[0].to(device))\n",
        "    preds = torch.argmax(torch.softmax(preds, dim=1), dim=1)\n",
        "\n",
        "    # Converting this problem to a 21 class problem\n",
        "    preds = np.array([encoder_21.get_label(pred.cpu()) if pred < 20 else \"other\" for pred in preds])\n",
        "    labels = np.array([label if encoder_21.get_idx(label) < 20 else \"other\" for label in labels])\n",
        "\n",
        "    plt.figure(figsize=(20, 8))\n",
        "\n",
        "    num_matches = 0\n",
        "    for idx in range(num_rows*num_cols):\n",
        "        ax = plt.subplot(num_rows, num_cols, idx + 1)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        img = plt.imread(imgs.path.iloc[idx])\n",
        "        plt.imshow(img)\n",
        "\n",
        "        title = labels[idx] + \" : \" + preds[idx]\n",
        "        title_obj = plt.title(title, fontdict={'fontsize':13})\n",
        "\n",
        "        if labels[idx] == preds[idx]:\n",
        "            num_matches += 1\n",
        "            plt.setp(title_obj, color='g')\n",
        "        else:\n",
        "            plt.setp(title_obj, color='r')\n",
        "\n",
        "        acc = num_matches/(idx+1)\n",
        "    print(\"Prediction accuracy: \", int(100*acc)/100)\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c848aa16",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T15:29:28.895503Z",
          "iopub.status.busy": "2023-11-09T15:29:28.895106Z",
          "iopub.status.idle": "2023-11-09T15:29:31.699970Z",
          "shell.execute_reply": "2023-11-09T15:29:31.698984Z"
        },
        "id": "c848aa16",
        "outputId": "9acf1bb9-9ec9-4226-8a85-9a435a754d19",
        "papermill": {
          "duration": 3.206872,
          "end_time": "2023-11-09T15:29:31.714400",
          "exception": false,
          "start_time": "2023-11-09T15:29:28.507528",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\Renuka/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n",
            "100%|| 30.8M/30.8M [00:23<00:00, 1.39MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load a pre-trained DenseNet model\n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "# Get the number of input features for the classifier\n",
        "num_ftrs = model.classifier.in_features\n",
        "\n",
        "# Modify the classifier layer to match the number of classes in your dataset\n",
        "model.classifier = nn.Linear(num_ftrs, len(classes))\n",
        "\n",
        "# Move the model to the appropriate device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3643bae0",
      "metadata": {
        "id": "3643bae0",
        "papermill": {
          "duration": 0.376025,
          "end_time": "2023-11-09T15:29:32.472846",
          "exception": false,
          "start_time": "2023-11-09T15:29:32.096821",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**saving the model results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "f7c85ab1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T15:29:33.282619Z",
          "iopub.status.busy": "2023-11-09T15:29:33.281773Z",
          "iopub.status.idle": "2023-11-09T15:29:33.487843Z",
          "shell.execute_reply": "2023-11-09T15:29:33.486981Z"
        },
        "id": "f7c85ab1",
        "papermill": {
          "duration": 0.583374,
          "end_time": "2023-11-09T15:29:33.490230",
          "exception": false,
          "start_time": "2023-11-09T15:29:32.906856",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Example of defining history with a best_model key\n",
        "history = {\n",
        "    'best_model': model.state_dict()  # Assuming model is your trained model\n",
        "}\n",
        "\n",
        "# Now you can save the best model's state dictionary\n",
        "torch.save(history['best_model'], \"./solution.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "6af199cc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-09T15:29:34.265324Z",
          "iopub.status.busy": "2023-11-09T15:29:34.264953Z",
          "iopub.status.idle": "2023-11-09T15:29:34.270917Z",
          "shell.execute_reply": "2023-11-09T15:29:34.269687Z"
        },
        "id": "6af199cc",
        "outputId": "2e3bfe3f-6a47-4583-84fd-30e7c9b29e68",
        "papermill": {
          "duration": 0.406036,
          "end_time": "2023-11-09T15:29:34.272720",
          "exception": false,
          "start_time": "2023-11-09T15:29:33.866684",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "solution.pth exists in the current directory.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if os.path.exists(\"./solution.pth\"):\n",
        "    print(\"solution.pth exists in the current directory.\")\n",
        "else:\n",
        "    print(\"solution.pth does not exist in the current directory.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 8544,
          "sourceId": 11959,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30715,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3171.546489,
      "end_time": "2023-11-09T15:29:37.124962",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-11-09T14:36:45.578473",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
